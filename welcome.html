<html>
<head>
    <title>
        Fantacy about cyber technology!.
    </title>
</head>
<body> 
    <h2 align="center"> DEEPSHEK VS OPEN artificial technology.</h2>
    <P>
        <center><b> How DeepSeek’s AI Stacks Up Against OpenAI’s Model </b></center>
        <b>C</b>hinese startup’s AI model, R1, goes head-to-head with OpenAI’s capabilities. But they are also very different.
DeepSeek has touted its latest AI model, R1, as being particularly good at problem solving, performing on par with OpenAI’s o1 reasoning model but at a fraction of the cost per use. Photo: Andre M. Chang/Zuma Press
It’s impossible to look at the Chinese artificial intelligence startup DeepSeek’s new AI model without comparing it against OpenAI, the dominant American rival.

DeepSeek has touted its latest AI model, R1, as being particularly good at problem solving, performing on par with OpenAI’s o1 reasoning model—but at a fraction of the cost per use. A DeepSeek app currently tops iPhone download rankings for the U.S.<br>
OpenAI said Wednesday it is investigating whether DeepSeek trained its new chatbot by repeatedly querying its AI models.

Just as DeepSeek and OpenAI are very different companies, R1 and o1 are also different technologies. Here’s a look at five ways the technologies share similarities and are different.

Wall Street Journal owner News Corp has a content-licensing partnership with OpenAI.
        <hr>  
              <h2>How DeepSeek works</h2>

DeepSeek reduced the data processing needed to train models, using its own inventions as well as techniques adopted by similarly constrained Chinese AI companies, The Wall Street Journal earlier reported. 

In addition to cutting down on data processing—offering massive savings in time and computing costs—DeepSeek uses a technique called “mixture of experts.” DeepSeek and some other AI developers do something akin to delegating questions to experts in specific fields. Each expert needs less training, easing the demand on chips to do everything at once.

“The techniques they implemented aren’t new but applying them at the scale they did, with the conviction they had was novel,” said Luke Arrigoni, CEO of Loti AI, an AI-based internet privacy platform. 

The Chinese company’s approach requires less time and power before a question is asked of the AI model, but uses more time and power to answer. The model shows how it reached an answer through “chain-of-thought” reasoning, a technique in which the technology gets better at a complex task one step at a time, according to Lin Qiao, CEO and co-founder of AI startup Fireworks AI
OpenAI’s o1 model uses chain-of-thought reasoning but doesn’t show users what is happening behind the scenes, Qiao said. Taking it a step further, the reasoning DeepSeek’s model produces can be used to train a smaller AI model, she added.

Both o1 and DeepSeek’s R1 are capable of what are considered “reasoning” tasks, like writing a business plan or creating a crossword puzzle.
        <hr>
        <h2>Performance</h2>
Researchers behind DeepSeek say they tested R1 against some of the top AI models from OpenAI and found it was very competitive. The evaluations included one developed by OpenAI involving computer-programming tasks an AI model must complete on its own, such as patching a bug in software. 

        <br>
R1 performed on par with OpenAI’s o1 and outperformed an earlier model called o1-mini. 

Qiao said members of the open-source community have already created a much smaller version of R1, which can be used on mobile phones and tablets.

Some users have said R1’s writing and problem-solving skills are impressive but note the model performed worse than rivals like OpenAI’s o1 on specific types of problem solving.

OpenAI CEO Sam Altman on Monday called R1 “an impressive model, particularly around what they’re able to deliver for the price,” in a post on X. He also said it was invigorating to have a new competitor and his company would move up some of its product releases.
        <hr>
       <h2>Cost</h2>
DeepSeek said it achieved results on par with OpenAI’s at lower cost and without top-performing chips. Some estimates have posited DeepSeek needed only around $5 million worth of chips to train one of its earlier models, but that ignores the cost of the research and experimentation for its development, Bernstein Research analyst Stacy Rasgon said in a research note.

The Morning Download delivers daily insights and news on business technology from the CIO Journal.

It isn’t clear how much computing power DeepSeek used for the more advanced R1 model.

In contrast, OpenAI has said training its GPT-4 model cost more than $100 million, and future AI models are expected to push past $1 billion.

For OpenAI’s next model, called GPT-5, a six-month training run can cost around half a billion dollars in computing costs alone, based on public and private estimates.
        <hr>
        <h2>Privacy and security</h2>
Users of DeepSeek’s latest flagship model, called V3, have noticed it refuses to answer sensitive political questions about China and its leader Xi Jinping. In some cases, the product responds in line with Beijing’s propaganda rather than including the perspective of government critics, as ChatGPT does. 

Still, R1 is freely available to download and use so some users feel more comfortable using it on their own servers, or those hosted by U.S. companies. The AI startup Liner is open to using DeepSeek’s R1, its Chief Executive Luke Kim said, because it is open-source and changing out AI models is easy.

By comparison, OpenAI has said it has a “new safety training approach” forcing its o1 model to adhere to company guidelines. OpenAI said it aims to prevent “jailbreaking” of AI models, and has formal agreements with the U.S. and U.K. AI safety institutes. Jailbreaking AI models involves manipulating them or trying to bypass their safety controls.
        <hr>
        <h2>Open-source versus proprietary</h2>
DeepSeek has released the “weights,” or numerical parameters, behind its R1 model for the public to freely use, download and modify. But it stopped short of releasing training data behind it, leading some to say the model isn’t fully “open-source.”

The Chinese company released a report detailing how it trained its model, which AI experts say helps developers decipher how DeepSeek accomplished its innovation.

The release of model weights also means developers can download the model to use. Hugging Face, which operates an open-source model-sharing platform, said the R1 models created by its community had been downloaded 3.2 million times.<br></br>        Unlike DeepSeek, OpenAI’s o1 is proprietary, meaning consumers and businesses pay the company to use its model and services. While some companies prefer to use proprietary technologies—because they are vetted by their builders and come with built-in cybersecurity controls—others prefer open-source technologies because they are easier to customize and control.
Tech leaders can prepare for and embrace this next era of intelligent organizational transformation as AI agents expand generative AI applications across industries
Autonomous Generative AI Agents Are Coming: 4 Ways to Prepare
Agentic AI could increase knowledge workers’ productivity and make workflows of all kinds more efficient—but it may take time before adoption is widespread, Deloitte predicts
        <hr>
        <h2>What’s Next for AI in 2025?</h2>
While large language models continue to advance, new models and agents are proving to be more effective at discrete tasks, according to Deloitte’s 16th annual ‘Tech Trends’ report
The Wall Street Journal news department was not involved in the creation of this content.
OpenAI Is Probing Whether DeepSeek Used Its Models to Train New Chatbot
Silicon Valley-based company says Chinese entities have tried to exfiltrate data from its tools
Whatever else the DeepSeek panic says, chatbots are ready to do real work around the house.
Why ‘Distillation’ Has Become the Scariest Word for AI Companies
DeepSeek’s success learning from bigger AI models raises questions about the billions being spent on the most advanced technology.
        <hr>
        <h2>What to Know About China’s DeepSeek AI</h2>
The Chinese upstart says it trained high-performing AI models cheaply, without using the most advanced chips.
How a Free Software Strategy Catapulted DeepSeek to AI Stardom
The Chinese AI upstart made the shrewd bet that American developers will latch on to its technology because it is open-source.
        <hr>
        <h2>Deepsheep's impact on the stock market.</h2>
        
Chinese AI company DeepSeek is stoking uncertainty for existing Big Tech players and raising questions about U.S. competitiveness. But enterprises, frustrated by the high cost of artificial intelligence over the last two years, are feeling pretty positive about the development.
How tech’s DeepSeek wake-up call could leave Nvidia stronger
DeepSeek shatters the myth that AI supremacy requires a billion-dollar checkbook.
    </P>
    
    
</body>

</html>